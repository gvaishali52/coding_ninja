{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem-1 : Count of Flower\n",
    "Problem Statement :\n",
    "Find and print count of each kind of flower (separated by space)?\n",
    "\n",
    "Note: Get the dataset from 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "Print the count as Integer Value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = ['sl','sw','pl','pw','flower_type']\n",
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', names=columns)\n",
    "count = iris['flower_type'].value_counts() \n",
    "print(count[0],count[1],count[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement :\n",
    "\n",
    "Find the data of flower “Iris-virginica” type where petal-length > 1.5?\n",
    "\n",
    "Print the all the feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.3 3.3 6.0 2.5 Iris-virginica\n",
      "<class 'type'> [6.3 3.3 6.0 2.5 'Iris-virginica']\n",
      "5.8 2.7 5.1 1.9 Iris-virginica\n",
      "<class 'type'> [5.8 2.7 5.1 1.9 'Iris-virginica']\n",
      "7.1 3.0 5.9 2.1 Iris-virginica\n",
      "<class 'type'> [7.1 3.0 5.9 2.1 'Iris-virginica']\n",
      "6.3 2.9 5.6 1.8 Iris-virginica\n",
      "<class 'type'> [6.3 2.9 5.6 1.8 'Iris-virginica']\n",
      "6.5 3.0 5.8 2.2 Iris-virginica\n",
      "<class 'type'> [6.5 3.0 5.8 2.2 'Iris-virginica']\n",
      "7.6 3.0 6.6 2.1 Iris-virginica\n",
      "<class 'type'> [7.6 3.0 6.6 2.1 'Iris-virginica']\n",
      "4.9 2.5 4.5 1.7 Iris-virginica\n",
      "<class 'type'> [4.9 2.5 4.5 1.7 'Iris-virginica']\n",
      "7.3 2.9 6.3 1.8 Iris-virginica\n",
      "<class 'type'> [7.3 2.9 6.3 1.8 'Iris-virginica']\n",
      "6.7 2.5 5.8 1.8 Iris-virginica\n",
      "<class 'type'> [6.7 2.5 5.8 1.8 'Iris-virginica']\n",
      "7.2 3.6 6.1 2.5 Iris-virginica\n",
      "<class 'type'> [7.2 3.6 6.1 2.5 'Iris-virginica']\n",
      "6.5 3.2 5.1 2.0 Iris-virginica\n",
      "<class 'type'> [6.5 3.2 5.1 2.0 'Iris-virginica']\n",
      "6.4 2.7 5.3 1.9 Iris-virginica\n",
      "<class 'type'> [6.4 2.7 5.3 1.9 'Iris-virginica']\n",
      "6.8 3.0 5.5 2.1 Iris-virginica\n",
      "<class 'type'> [6.8 3.0 5.5 2.1 'Iris-virginica']\n",
      "5.7 2.5 5.0 2.0 Iris-virginica\n",
      "<class 'type'> [5.7 2.5 5.0 2.0 'Iris-virginica']\n",
      "5.8 2.8 5.1 2.4 Iris-virginica\n",
      "<class 'type'> [5.8 2.8 5.1 2.4 'Iris-virginica']\n",
      "6.4 3.2 5.3 2.3 Iris-virginica\n",
      "<class 'type'> [6.4 3.2 5.3 2.3 'Iris-virginica']\n",
      "6.5 3.0 5.5 1.8 Iris-virginica\n",
      "<class 'type'> [6.5 3.0 5.5 1.8 'Iris-virginica']\n",
      "7.7 3.8 6.7 2.2 Iris-virginica\n",
      "<class 'type'> [7.7 3.8 6.7 2.2 'Iris-virginica']\n",
      "7.7 2.6 6.9 2.3 Iris-virginica\n",
      "<class 'type'> [7.7 2.6 6.9 2.3 'Iris-virginica']\n",
      "6.0 2.2 5.0 1.5 Iris-virginica\n",
      "<class 'type'> [6.0 2.2 5.0 1.5 'Iris-virginica']\n",
      "6.9 3.2 5.7 2.3 Iris-virginica\n",
      "<class 'type'> [6.9 3.2 5.7 2.3 'Iris-virginica']\n",
      "5.6 2.8 4.9 2.0 Iris-virginica\n",
      "<class 'type'> [5.6 2.8 4.9 2.0 'Iris-virginica']\n",
      "7.7 2.8 6.7 2.0 Iris-virginica\n",
      "<class 'type'> [7.7 2.8 6.7 2.0 'Iris-virginica']\n",
      "6.3 2.7 4.9 1.8 Iris-virginica\n",
      "<class 'type'> [6.3 2.7 4.9 1.8 'Iris-virginica']\n",
      "6.7 3.3 5.7 2.1 Iris-virginica\n",
      "<class 'type'> [6.7 3.3 5.7 2.1 'Iris-virginica']\n",
      "7.2 3.2 6.0 1.8 Iris-virginica\n",
      "<class 'type'> [7.2 3.2 6.0 1.8 'Iris-virginica']\n",
      "6.2 2.8 4.8 1.8 Iris-virginica\n",
      "<class 'type'> [6.2 2.8 4.8 1.8 'Iris-virginica']\n",
      "6.1 3.0 4.9 1.8 Iris-virginica\n",
      "<class 'type'> [6.1 3.0 4.9 1.8 'Iris-virginica']\n",
      "6.4 2.8 5.6 2.1 Iris-virginica\n",
      "<class 'type'> [6.4 2.8 5.6 2.1 'Iris-virginica']\n",
      "7.2 3.0 5.8 1.6 Iris-virginica\n",
      "<class 'type'> [7.2 3.0 5.8 1.6 'Iris-virginica']\n",
      "7.4 2.8 6.1 1.9 Iris-virginica\n",
      "<class 'type'> [7.4 2.8 6.1 1.9 'Iris-virginica']\n",
      "7.9 3.8 6.4 2.0 Iris-virginica\n",
      "<class 'type'> [7.9 3.8 6.4 2.0 'Iris-virginica']\n",
      "6.4 2.8 5.6 2.2 Iris-virginica\n",
      "<class 'type'> [6.4 2.8 5.6 2.2 'Iris-virginica']\n",
      "6.3 2.8 5.1 1.5 Iris-virginica\n",
      "<class 'type'> [6.3 2.8 5.1 1.5 'Iris-virginica']\n",
      "6.1 2.6 5.6 1.4 Iris-virginica\n",
      "<class 'type'> [6.1 2.6 5.6 1.4 'Iris-virginica']\n",
      "7.7 3.0 6.1 2.3 Iris-virginica\n",
      "<class 'type'> [7.7 3.0 6.1 2.3 'Iris-virginica']\n",
      "6.3 3.4 5.6 2.4 Iris-virginica\n",
      "<class 'type'> [6.3 3.4 5.6 2.4 'Iris-virginica']\n",
      "6.4 3.1 5.5 1.8 Iris-virginica\n",
      "<class 'type'> [6.4 3.1 5.5 1.8 'Iris-virginica']\n",
      "6.0 3.0 4.8 1.8 Iris-virginica\n",
      "<class 'type'> [6.0 3.0 4.8 1.8 'Iris-virginica']\n",
      "6.9 3.1 5.4 2.1 Iris-virginica\n",
      "<class 'type'> [6.9 3.1 5.4 2.1 'Iris-virginica']\n",
      "6.7 3.1 5.6 2.4 Iris-virginica\n",
      "<class 'type'> [6.7 3.1 5.6 2.4 'Iris-virginica']\n",
      "6.9 3.1 5.1 2.3 Iris-virginica\n",
      "<class 'type'> [6.9 3.1 5.1 2.3 'Iris-virginica']\n",
      "5.8 2.7 5.1 1.9 Iris-virginica\n",
      "<class 'type'> [5.8 2.7 5.1 1.9 'Iris-virginica']\n",
      "6.8 3.2 5.9 2.3 Iris-virginica\n",
      "<class 'type'> [6.8 3.2 5.9 2.3 'Iris-virginica']\n",
      "6.7 3.3 5.7 2.5 Iris-virginica\n",
      "<class 'type'> [6.7 3.3 5.7 2.5 'Iris-virginica']\n",
      "6.7 3.0 5.2 2.3 Iris-virginica\n",
      "<class 'type'> [6.7 3.0 5.2 2.3 'Iris-virginica']\n",
      "6.3 2.5 5.0 1.9 Iris-virginica\n",
      "<class 'type'> [6.3 2.5 5.0 1.9 'Iris-virginica']\n",
      "6.5 3.0 5.2 2.0 Iris-virginica\n",
      "<class 'type'> [6.5 3.0 5.2 2.0 'Iris-virginica']\n",
      "6.2 3.4 5.4 2.3 Iris-virginica\n",
      "<class 'type'> [6.2 3.4 5.4 2.3 'Iris-virginica']\n",
      "5.9 3.0 5.1 1.8 Iris-virginica\n",
      "<class 'type'> [5.9 3.0 5.1 1.8 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = ['sl','sw','pl','pw','flower_type']\n",
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', names=columns)\n",
    "iris = iris[iris.flower_type=='Iris-virginica']\n",
    "iris = iris[iris.pl>1.5]\n",
    "iris = iris.values\n",
    "for row in iris :\n",
    "    print(*row)\n",
    "    print(type,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and print the minimum, maximum and average value of the feature for each kind of flower ?\n",
    "\n",
    "Print the value with two decimal places.\n",
    "\n",
    "Note: Order for flower is Iris-setosa, Iris-versicolor and Iris-virginica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.30 2.30 1.00 0.10 Iris-setosa\n",
      "5.80 4.40 1.90 0.60 Iris-setosa\n",
      "5.01 3.42 1.46 0.24 Iris-setosa\n",
      "4.90 2.00 3.00 1.00 Iris-versicolor\n",
      "7.00 3.40 5.10 1.80 Iris-versicolor\n",
      "5.94 2.77 4.26 1.33 Iris-versicolor\n",
      "4.90 2.20 4.50 1.40 Iris-virginica\n",
      "7.90 3.80 6.90 2.50 Iris-virginica\n",
      "6.59 2.97 5.55 2.03 Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = ['sl','sw','pl','pw','flower_type']\n",
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', names=columns)\n",
    "\n",
    "c = iris[iris.flower_type=='Iris-setosa']\n",
    "print('%.2f'%min(c['sl']),'%.2f'%min(c['sw']),'%.2f'%min(c['pl']),'%.2f'%min(c['pw']),c.iloc[0,4])\n",
    "print('%.2f'%max(c['sl']),'%.2f'%max(c['sw']),'%.2f'%max(c['pl']),'%.2f'%max(c['pw']),c.iloc[0,4])\n",
    "print('%.2f'%(c['sl'].mean()),'%.2f'%(c['sw'].mean()),'%.2f'%(c['pl'].mean()),'%.2f'%(c['pw'].mean()),c.iloc[0,4])\n",
    "\n",
    "c1 = iris[iris.flower_type=='Iris-versicolor']\n",
    "print('%.2f'%min(c1['sl']),'%.2f'%min(c1['sw']),'%.2f'%min(c1['pl']),'%.2f'%min(c1['pw']),c1.iloc[0,4])\n",
    "print('%.2f'%max(c1['sl']),'%.2f'%max(c1['sw']),'%.2f'%max(c1['pl']),'%.2f'%max(c1['pw']),c1.iloc[0,4])\n",
    "print('%.2f'%(c1['sl'].mean()),'%.2f'%(c1['sw'].mean()),'%.2f'%(c1['pl'].mean()),'%.2f'%(c1['pw'].mean()),c1.iloc[0,4])\n",
    "\n",
    "c2 = iris[iris.flower_type=='Iris-virginica']\n",
    "print('%.2f'%min(c2['sl']),'%.2f'%min(c2['sw']),'%.2f'%min(c2['pl']),'%.2f'%min(c2['pw']),c2.iloc[0,4])\n",
    "print('%.2f'%max(c2['sl']),'%.2f'%max(c2['sw']),'%.2f'%max(c2['pl']),'%.2f'%max(c2['pw']),c2.iloc[0,4])\n",
    "print('%.2f'%(c2['sl'].mean()),'%.2f'%(c2['sw'].mean()),'%.2f'%(c2['pl'].mean()),'%.2f'%(c2['pw'].mean()),c2.iloc[0,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment\n",
    "\n",
    "Given file \"terrorismData.csv\" It is an open-source database including information on terrorist attacks around the world from 1970 through 2017. This dataset includes systematic data on domestic as well as international terrorist incidents that have occurred during this time period\n",
    "\n",
    "#### Terror Attack City\n",
    "\n",
    "Problem Statement :\n",
    "\n",
    "The Most Dangerous city in Jammu and Kashmir and the terrorist group which is most active in that city?\n",
    "\n",
    "Print count of number of attacks in that city as integer value.\n",
    "Note:Ignoring the Unknown Terrorist Group.Here Dangerous related with the number of terrorist attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/pandas/terrorismData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sgupt\\OneDrive\\Pictures\\Documents\\GitHub\\coding_ninja\\pandas\\12_ pandas.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/pandas/12_%20pandas.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/pandas/12_%20pandas.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mdata/pandas/terrorismData.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/pandas/12_%20pandas.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39mState\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mJammu and Kashmir\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/pandas/12_%20pandas.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_list \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mCity\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32mc:\\Users\\sgupt\\anaconda3\\envs\\vaishali\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sgupt\\anaconda3\\envs\\vaishali\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\sgupt\\anaconda3\\envs\\vaishali\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\sgupt\\anaconda3\\envs\\vaishali\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\sgupt\\anaconda3\\envs\\vaishali\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\sgupt\\anaconda3\\envs\\vaishali\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/pandas/terrorismData.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/pandas/terrorismData.csv')\n",
    "\n",
    "df = df[df.State=='Jammu and Kashmir']\n",
    "df_list = df['City'].value_counts()\n",
    "city = df_list.index[0]\n",
    "count = df_list.values[0]\n",
    "\n",
    "df = df[df['City']==city]\n",
    "group = df['Group'].value_counts().index[1]\n",
    "\n",
    "print(city,count,group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terror Government\n",
    "\n",
    "Problem Statement :\n",
    "There was formation of new government in India on 26 May 2014. So current government's span is from 26th May 2014 to current. Find out two things from this period-\n",
    "\n",
    "1. Total number of attacks done in this period in India. Find this count as integer.\n",
    "2. Which Terrorist group was most active in this period in India. Most active means group which has done maximum number of attacks.\n",
    "3. Ignore the Unknown group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3336 Maoists\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('data/pandas/terrorismData.csv')\n",
    "\n",
    "a = df[df.Day>=26]\n",
    "b = a[a.Year==2014]\n",
    "c = b[b.Country=='India']\n",
    "ans1 = c[c.Month==5]\n",
    "\n",
    "d = df[df.Year==2014]\n",
    "e = d[d.Country=='India']\n",
    "ans2 = e[e.Month>5]\n",
    "\n",
    "f = df[df.Country=='India']\n",
    "ans3 = f[f.Year>2014]\n",
    "\n",
    "count = ans1.shape[0] + ans2.shape[0] + ans3.shape[0]\n",
    "\n",
    "ans1=ans1[ans1.Group!='Unknown']\n",
    "ans2=ans2[ans2.Group!='Unknown']\n",
    "ans3=ans3[ans3.Group!='Unknown']\n",
    "\n",
    "print(count,ans3.Group.describe().top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terror Attack\n",
    "Problem Statement :\n",
    "\n",
    "Find out the Country with Highest Number of Terror Attack and in which year the most number of terrorist attack happened in that country ?\n",
    "Print count of terror attacks as integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iraq 24636 2014\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/pandas/terrorismData.csv')\n",
    "\n",
    "df_list = df['Country'].value_counts()\n",
    "country = df_list.index[0]\n",
    "attack = df_list.values[0]\n",
    "\n",
    "df = df[df['Country']==country]\n",
    "year = df['Year'].value_counts().index[0]\n",
    "\n",
    "print(country,attack,year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terror DeadliestAttack\n",
    "\n",
    "Problem Statement :\n",
    "\n",
    "Most Deadliest attack in a history of HumanKind?\n",
    "Print count of Killed people as integer value.\n",
    "\n",
    "Note: Here Deadliest attack means, in which the most number of people killed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570 Iraq Islamic State of Iraq and the Levant (ISIL)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/pandas/terrorismData.csv')\n",
    "\n",
    "df = df[df.Killed==df.Killed.max()]\n",
    "mx_killed = df.Killed.iloc[0]\n",
    "country = df.Country.iloc[0]\n",
    "group = df.Group.iloc[0]\n",
    "print(int(mx_killed), country, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terror Frequency\n",
    "\n",
    "Problem Statement :\n",
    "\n",
    "Find the frequency of the Casualty in Red Corridor states and in Jammu and Kashmir ?Here Frequency is (Total Casualty/Total Number of a year)\n",
    "Print frequency as integer value.\n",
    "\n",
    "Note:Red Corridor state includes Jharkhand, Odisha, Andhra Pradesh, and Chhattisgarh. Here Casualty=Killed +Wounded.Don't fill the nan value present in Killed and Wounded feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 261\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('data/pandas/terrorismData.csv')\n",
    "\n",
    "year = len(set(df['Year']))\n",
    "\n",
    "df = df[df.Country == 'India']\n",
    "df['Casualty'] = df['Killed'] + df['Wounded']\n",
    "\n",
    "jk = df[df.State == 'Jammu and Kashmir']\n",
    "rc = df[(df.State == 'Jharkhand') | (df.State == 'Odisha') | (df.State == 'Andhra Pradesh') | (df.State == 'Chhattisgarh')]\n",
    "\n",
    "jkc = int(np.sum(jk['Casualty']))\n",
    "rcc = int(np.sum(rc['Casualty']))\n",
    "\n",
    "print(rcc//year,jkc//year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('vaishali')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c626c7f027fd81c21c9d33e27e9da6944415f92c80192dd5d04cdc4b243efcd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
