{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent - Boston Dataset\n",
    "\n",
    "Boston dataset is one of the datasets available in sklearn.\n",
    "You are given a Training dataset csv file with X train and Y train data. As studied in lecture, your task is to come up with Gradient Descent algorithm and thus predictions for the test dataset given.\n",
    "\n",
    "Task is to:\n",
    "1. Code Gradient Descent for N features and come with predictions.\n",
    "2. Try and test with various combinations of learning rates and number of iterations.\n",
    "3. Try using Feature Scaling, and see if it helps you in getting better results. \n",
    "\n",
    "\n",
    "Instructions:\n",
    "1. Use Gradient Descent as a training algorithm and submit results predicted.\n",
    "2. Files are in csv format, you can use genfromtxt function in numpy to load data from csv file. Similarly you can use savetxt function to save data into a file.\n",
    "3. Submit a csv file with only predictions for X test data. File name should not have spaces. File should not have any headers and should only have one column i.e. predictions. Also predictions shouldn't be in exponential form. \n",
    "4. Your score is based on coefficient of determination.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "import numpy as np\n",
    "\n",
    "test_data = np.loadtxt(\"test_boston_x_test.csv\", delimiter=\",\")\n",
    "train_data = np.loadtxt(\"training_boston_x_y_train.csv\", delimiter=\",\")\n",
    "\n",
    "# test_data =pd.read_csv(\"test_boston_x_test.csv\")\n",
    "# train_data = pd.read_csv(\"training_boston_x_y_train.csv\", delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train dataset: (379, 14)\n",
      "Shape of test dataset: (127, 13)\n"
     ]
    }
   ],
   "source": [
    "## Shape of data: no. of row and columns\n",
    "print(\"Shape of train dataset:\",train_data.shape )\n",
    "print(\"Shape of test dataset:\",test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## description of only numerical columns training data\n",
    "## its a function of dataframe\n",
    "## .T means transpose: row to columns vice versa\n",
    "# train_data.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Info show the data type and not null values\n",
    "# train_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.tail().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## checking null values \n",
    "# train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are no null values, it means there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no NA values in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, using gradient descent, we will find the best values of m and c**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds the new gradient at each step\n",
    "def step_gradient(X,Y, learning_rate, m , c):\n",
    "    m_slope = np.array([0 for i in range(len(X[0]))])\n",
    "    c_slope = np.array([0 for i in range(len(X[0]))])\n",
    "    M = len(X)\n",
    "    for i in range(M):\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "        m_slope += (-2/M)* (y - m * x - c)*x\n",
    "        c_slope += (-2/M)* (y - m * x - c)\n",
    "    new_m = m - learning_rate * m_slope\n",
    "    new_c = c - learning_rate * c_slope\n",
    "    # return new_m, new_c\n",
    "    print(new_m, new_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds the new cost after each optimisation.\n",
    "def cost(X,Y ,m, c):\n",
    "    total_cost = 0\n",
    "    M = len(X)\n",
    "    for i in range(M):\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "        total_cost += (1/M)*((y - m*x - c)**2)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Gradient Descent Function\n",
    "def gd(X,Y, learning_rate, num_iterations):\n",
    "    m = 0       # Intial random value taken as 0\n",
    "    c = 0       # Intial random value taken as 0\n",
    "    for i in range(num_iterations):\n",
    "        m, c = step_gradient(x,y, learning_rate, m , c)\n",
    "        print(i, \" Cost: \", cost(X,Y, m, c))\n",
    "    return m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=train_data[:,:-1]\n",
    "y=train_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.append(x, np.ones(len(x), dtype='float64').reshape(-1, 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    learning_rate = 0.0001\n",
    "    num_iterations = 100\n",
    "    m, c = gd(x,y, learning_rate, num_iterations)\n",
    "    print(\"Final m :\", m)\n",
    "    print(\"Final c :\", c)\n",
    "    return m,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'add' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sgupt\\OneDrive\\Pictures\\Documents\\GitHub\\coding_ninja\\projects\\gradient_descent\\Gradient_Descent_Boston_Dataset\\Gradient_descent_boston_dataset.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m m, c \u001b[39m=\u001b[39m run()\n",
      "\u001b[1;32mc:\\Users\\sgupt\\OneDrive\\Pictures\\Documents\\GitHub\\coding_ninja\\projects\\gradient_descent\\Gradient_Descent_Boston_Dataset\\Gradient_descent_boston_dataset.ipynb Cell 19\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m learning_rate \u001b[39m=\u001b[39m \u001b[39m0.0001\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m num_iterations \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m m, c \u001b[39m=\u001b[39m gd(x,y, learning_rate, num_iterations)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinal m :\u001b[39m\u001b[39m\"\u001b[39m, m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinal c :\u001b[39m\u001b[39m\"\u001b[39m, c)\n",
      "\u001b[1;32mc:\\Users\\sgupt\\OneDrive\\Pictures\\Documents\\GitHub\\coding_ninja\\projects\\gradient_descent\\Gradient_Descent_Boston_Dataset\\Gradient_descent_boston_dataset.ipynb Cell 19\u001b[0m in \u001b[0;36mgd\u001b[1;34m(X, Y, learning_rate, num_iterations)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m c \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m       \u001b[39m# Intial random value taken as 0\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_iterations):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     m, c \u001b[39m=\u001b[39m step_gradient(x,y, learning_rate, m , c)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(i, \u001b[39m\"\u001b[39m\u001b[39m Cost: \u001b[39m\u001b[39m\"\u001b[39m, cost(X,Y, m, c))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m m, c\n",
      "\u001b[1;32mc:\\Users\\sgupt\\OneDrive\\Pictures\\Documents\\GitHub\\coding_ninja\\projects\\gradient_descent\\Gradient_Descent_Boston_Dataset\\Gradient_descent_boston_dataset.ipynb Cell 19\u001b[0m in \u001b[0;36mstep_gradient\u001b[1;34m(X, Y, learning_rate, m, c)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     x \u001b[39m=\u001b[39m X[i]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     y \u001b[39m=\u001b[39m Y[i]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     m_slope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m\u001b[39m/\u001b[39mM)\u001b[39m*\u001b[39m (y \u001b[39m-\u001b[39m m \u001b[39m*\u001b[39m x \u001b[39m-\u001b[39m c)\u001b[39m*\u001b[39mx\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     c_slope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m\u001b[39m/\u001b[39mM)\u001b[39m*\u001b[39m (y \u001b[39m-\u001b[39m m \u001b[39m*\u001b[39m x \u001b[39m-\u001b[39m c)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sgupt/OneDrive/Pictures/Documents/GitHub/coding_ninja/projects/gradient_descent/Gradient_Descent_Boston_Dataset/Gradient_descent_boston_dataset.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m new_m \u001b[39m=\u001b[39m m \u001b[39m-\u001b[39m learning_rate \u001b[39m*\u001b[39m m_slope\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "m, c = run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('vaishali')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c626c7f027fd81c21c9d33e27e9da6944415f92c80192dd5d04cdc4b243efcd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
